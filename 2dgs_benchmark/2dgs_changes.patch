diff --git a/render.py b/render.py
index d8e1381..cc1c180 100644
--- a/render.py
+++ b/render.py
@@ -66,8 +66,10 @@ if __name__ == "__main__":
     if (not args.skip_test) and (len(scene.getTestCameras()) > 0):
         print("export rendered testing images ...")
         os.makedirs(test_dir, exist_ok=True)
-        gaussExtractor.reconstruction(scene.getTestCameras())
+        fps = gaussExtractor.reconstruction(scene.getTestCameras())
         gaussExtractor.export_image(test_dir)
+        with open(os.path.join(test_dir, 'fps.txt'), 'w+') as f:
+            f.write(str(fps))
     
     
     if args.render_path:
diff --git a/train.py b/train.py
index 26631b8..545ab71 100644
--- a/train.py
+++ b/train.py
@@ -11,6 +11,7 @@
 
 import os
 import torch
+import time
 from random import randint
 from utils.loss_utils import l1_loss, ssim
 from gaussian_renderer import render, network_gui
@@ -50,6 +51,7 @@ def training(dataset, opt, pipe, testing_iterations, saving_iterations, checkpoi
     ema_normal_for_log = 0.0
 
     progress_bar = tqdm(range(first_iter, opt.iterations), desc="Training progress")
+    start_time = time.time()
     first_iter += 1
     for iteration in range(first_iter, opt.iterations + 1):        
 
@@ -166,6 +168,10 @@ def training(dataset, opt, pipe, testing_iterations, saving_iterations, checkpoi
                 except Exception as e:
                     # raise e
                     network_gui.conn = None
+    end_time = time.time() - start_time
+    print(f"writing: {scene.model_path + 'time.txt'}")
+    with open(os.path.join(scene.model_path, 'time.txt'), 'w+') as f:
+        f.write(str(round(end_time/60, 3)) + ' min')
 
 def prepare_output_and_logger(args):    
     if not args.model_path:
diff --git a/utils/mesh_utils.py b/utils/mesh_utils.py
index e9b1524..29b9f29 100644
--- a/utils/mesh_utils.py
+++ b/utils/mesh_utils.py
@@ -10,6 +10,7 @@
 #
 
 import torch
+import time
 import numpy as np
 import os
 import math
@@ -103,6 +104,13 @@ class GaussianExtractor(object):
         """
         self.clean()
         self.viewpoint_stack = viewpoint_stack
+        start_time = time.time()
+        for i, viewpoint_cam in tqdm(enumerate(self.viewpoint_stack), desc="reconstruct radiance fields"):
+            torch.cuda.synchronize()
+            render_pkg = self.render(viewpoint_cam, self.gaussians)
+            torch.cuda.synchronize()
+        frame_time = (time.time() - start_time)/i
+        fps = 1/frame_time
         for i, viewpoint_cam in tqdm(enumerate(self.viewpoint_stack), desc="reconstruct radiance fields"):
             render_pkg = self.render(viewpoint_cam, self.gaussians)
             rgb = render_pkg['render']
@@ -121,6 +129,7 @@ class GaussianExtractor(object):
         # self.alphamaps = torch.stack(self.alphamaps, dim=0)
         # self.depth_normals = torch.stack(self.depth_normals, dim=0)
         self.estimate_bounding_sphere()
+        return fps
 
     def estimate_bounding_sphere(self):
         """
